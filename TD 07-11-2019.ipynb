{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigml.api import BigML\n",
    "import numpy as np\n",
    "from pandas import DataFrame, read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltrain=read_csv('./cs-training.csv')\n",
    "test=read_csv('./td_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On met l'ID BigML, la key et l'id du projet\n",
    "\n",
    "api = BigML('CorantinO', '77225993ed8676123a26c4cdaa13cfadadf71237', project='project/5d94a41242129f2e16000244')\n",
    "\n",
    "#On importe nos deux fichiers csv fulltrainmodif et testmodif dans la source BigML\n",
    "\n",
    "trainfull_source = api.create_source('./cs-training.csv')\n",
    "test_source = api.create_source('./td_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On crée notre dataset trainfull et test\n",
    "\n",
    "trainfull_dataset = api.create_dataset(trainfull_source)\n",
    "test_dataset = api.create_dataset(test_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On split notre trainfull en 80-20\n",
    "\n",
    "split_train = api.create_dataset(\n",
    "    trainfull_dataset, {\"name\": \"TD GMSC | Training\", \"sample_rate\": 0.8, \"seed\": \"my seed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'un modèle Ensemble sur notre split train \n",
    "\n",
    "ensemble = api.create_ensemble(split_train , {\"objective_field\" : \"SeriousDlqin2yrs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Création batch prediction sur la partie notre test\n",
    "\n",
    "batch_prediction = api.create_batch_prediction(ensemble, test_dataset, {\"all_fields\": True, \"probability\": True})\n",
    "api.ok(batch_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BatchPrediction/GMSC_td.csv'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Téléchargement du batch prediction\n",
    "\n",
    "api.download_batch_prediction(batch_prediction3, filename='BatchPrediction/GMSC_td.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
